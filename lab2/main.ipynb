{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Series(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'])\n",
    "\n",
    "train_path = '../blobs/notMNIST_large'\n",
    "test_path = '../blobs/notMNIST_small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train files: 51696\n",
      "# of val files: 9360\n",
      "# of test files: 9364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_files = []\n",
    "y_train = []\n",
    "x_val_files = []\n",
    "y_val = []\n",
    "x_test_files = []\n",
    "y_test = []\n",
    "for label, index in zip(labels, labels.index):    \n",
    "    train_dir = os.path.join(train_path, label)\n",
    "    files = pd.Series(os.path.join(train_dir, name) for name in os.listdir(train_dir))\n",
    "    # NOTE: reducing the number of samples for faster processing\n",
    "    files = files.sample(len(files) // 10)\n",
    "    x_train_files.extend(files)\n",
    "    y_train.extend(index for _ in range(len(files)))\n",
    "    \n",
    "    # val and test must come from the same distribution\n",
    "    test_dir = os.path.join(test_path, label)\n",
    "    test_files = [os.path.join(test_dir, name) for name in os.listdir(test_dir)]\n",
    "    val, test = train_test_split(test_files, test_size=0.5)\n",
    "    x_val_files.extend(val)\n",
    "    y_val.extend(index for _ in range(len(val)))\n",
    "    x_test_files.extend(test)\n",
    "    y_test.extend(index for _ in range(len(test)))\n",
    "    \n",
    "print('# of train files:', len(x_train_files))\n",
    "assert(len(x_train_files) == len(y_train))\n",
    "print('# of val files:', len(x_val_files))\n",
    "assert(len(x_val_files) == len(y_val))\n",
    "print('# of test files:', len(x_test_files))\n",
    "assert(len(x_test_files) == len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling file names to avoid labels being consecutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.shuffle_in_unison(x_train_files, y_train)\n",
    "main.shuffle_in_unison(x_val_files, y_val)\n",
    "main.shuffle_in_unison(x_test_files, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: (9364, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([main.load_image(file) for file in x_test_files])\n",
    "y_test = np.array(y_test)\n",
    "x_test = x_test / 255.0\n",
    "print('Test set:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51696, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([main.load_image(file) for file in x_train_files])\n",
    "y_train= np.array(y_train)\n",
    "x_train = x_train / 255.0\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: (9360, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "x_val = np.array([main.load_image(file) for file in x_val_files])\n",
    "y_val= np.array(y_val)\n",
    "x_val = x_val / 255.0\n",
    "print('Validation set:', x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(150, activation='relu'),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='SGD', \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51696/51696 [==============================] - 3s 56us/sample - loss: 0.8119 - acc: 0.7819\n",
      "Epoch 2/30\n",
      "51696/51696 [==============================] - 3s 53us/sample - loss: 0.6114 - acc: 0.8279\n",
      "Epoch 3/30\n",
      "51696/51696 [==============================] - 3s 58us/sample - loss: 0.5632 - acc: 0.8377\n",
      "Epoch 4/30\n",
      "51696/51696 [==============================] - 3s 56us/sample - loss: 0.5315 - acc: 0.8464\n",
      "Epoch 5/30\n",
      "51696/51696 [==============================] - 3s 54us/sample - loss: 0.5068 - acc: 0.8525\n",
      "Epoch 6/30\n",
      "51696/51696 [==============================] - 3s 53us/sample - loss: 0.4857 - acc: 0.8574\n",
      "Epoch 7/30\n",
      "51696/51696 [==============================] - 3s 55us/sample - loss: 0.4682 - acc: 0.8628\n",
      "Epoch 8/30\n",
      "51696/51696 [==============================] - 3s 58us/sample - loss: 0.4522 - acc: 0.8661\n",
      "Epoch 9/30\n",
      "51696/51696 [==============================] - 3s 59us/sample - loss: 0.4364 - acc: 0.8710\n",
      "Epoch 10/30\n",
      "51696/51696 [==============================] - 3s 55us/sample - loss: 0.4229 - acc: 0.8749\n",
      "Epoch 11/30\n",
      "51696/51696 [==============================] - 3s 58us/sample - loss: 0.4097 - acc: 0.8789\n",
      "Epoch 12/30\n",
      "51696/51696 [==============================] - 3s 55us/sample - loss: 0.3974 - acc: 0.8823\n",
      "Epoch 13/30\n",
      "51696/51696 [==============================] - 3s 54us/sample - loss: 0.3865 - acc: 0.8856\n",
      "Epoch 14/30\n",
      "51696/51696 [==============================] - 3s 54us/sample - loss: 0.3747 - acc: 0.8887\n",
      "Epoch 15/30\n",
      "51696/51696 [==============================] - 3s 56us/sample - loss: 0.3650 - acc: 0.8918\n",
      "Epoch 16/30\n",
      "51696/51696 [==============================] - 3s 56us/sample - loss: 0.3543 - acc: 0.8949\n",
      "Epoch 17/30\n",
      "51696/51696 [==============================] - 3s 63us/sample - loss: 0.3439 - acc: 0.8983\n",
      "Epoch 18/30\n",
      "51696/51696 [==============================] - 3s 52us/sample - loss: 0.3349 - acc: 0.9006\n",
      "Epoch 19/30\n",
      "51696/51696 [==============================] - 3s 51us/sample - loss: 0.3252 - acc: 0.9043\n",
      "Epoch 20/30\n",
      "51696/51696 [==============================] - 3s 54us/sample - loss: 0.3173 - acc: 0.9064\n",
      "Epoch 21/30\n",
      "51696/51696 [==============================] - 3s 57us/sample - loss: 0.3078 - acc: 0.9088\n",
      "Epoch 22/30\n",
      "51696/51696 [==============================] - 3s 50us/sample - loss: 0.3001 - acc: 0.9115\n",
      "Epoch 23/30\n",
      "51696/51696 [==============================] - 3s 50us/sample - loss: 0.2923 - acc: 0.9144\n",
      "Epoch 24/30\n",
      "51696/51696 [==============================] - 3s 50us/sample - loss: 0.2840 - acc: 0.9171\n",
      "Epoch 25/30\n",
      "51696/51696 [==============================] - 3s 50us/sample - loss: 0.2761 - acc: 0.9188\n",
      "Epoch 26/30\n",
      "51696/51696 [==============================] - 3s 56us/sample - loss: 0.2691 - acc: 0.9202\n",
      "Epoch 27/30\n",
      "51696/51696 [==============================] - 3s 56us/sample - loss: 0.2608 - acc: 0.92310s - loss: 0.2\n",
      "Epoch 28/30\n",
      "51696/51696 [==============================] - 3s 63us/sample - loss: 0.2531 - acc: 0.9253\n",
      "Epoch 29/30\n",
      "51696/51696 [==============================] - 4s 75us/sample - loss: 0.2458 - acc: 0.9285\n",
      "Epoch 30/30\n",
      "51696/51696 [==============================] - 3s 53us/sample - loss: 0.2390 - acc: 0.9296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f464d128630>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction:\n",
      "9364/9364 [==============================] - 0s 42us/sample - loss: 0.2560 - acc: 0.9244\n"
     ]
    }
   ],
   "source": [
    "print('Test prediction:')\n",
    "score, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression was at about 88% accuracy on 50k train samples. Here we got **92.5%** without any fine-tuning, although the model overits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try **regularization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(150, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(50, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(10, kernel_regularizer=keras.regularizers.l2(0.0001))\n",
    "])\n",
    "reg_model.compile(\n",
    "    optimizer='sgd', \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51696/51696 [==============================] - 4s 73us/sample - loss: 0.9359 - acc: 0.7376\n",
      "Epoch 2/30\n",
      "51696/51696 [==============================] - 3s 67us/sample - loss: 0.6760 - acc: 0.8160\n",
      "Epoch 3/30\n",
      "51696/51696 [==============================] - 3s 64us/sample - loss: 0.6259 - acc: 0.8265\n",
      "Epoch 4/30\n",
      "51696/51696 [==============================] - 4s 70us/sample - loss: 0.5946 - acc: 0.8348\n",
      "Epoch 5/30\n",
      "51696/51696 [==============================] - 4s 70us/sample - loss: 0.5759 - acc: 0.8405\n",
      "Epoch 6/30\n",
      "51696/51696 [==============================] - 5s 99us/sample - loss: 0.5601 - acc: 0.8442\n",
      "Epoch 7/30\n",
      "51696/51696 [==============================] - 4s 86us/sample - loss: 0.5441 - acc: 0.8490\n",
      "Epoch 8/30\n",
      "51696/51696 [==============================] - 4s 69us/sample - loss: 0.5307 - acc: 0.8525\n",
      "Epoch 9/30\n",
      "51696/51696 [==============================] - 4s 77us/sample - loss: 0.5187 - acc: 0.85592s - \n",
      "Epoch 10/30\n",
      "51696/51696 [==============================] - 4s 79us/sample - loss: 0.5084 - acc: 0.8581\n",
      "Epoch 11/30\n",
      "51696/51696 [==============================] - 4s 71us/sample - loss: 0.4987 - acc: 0.8612\n",
      "Epoch 12/30\n",
      "51696/51696 [==============================] - 4s 83us/sample - loss: 0.4884 - acc: 0.8638\n",
      "Epoch 13/30\n",
      "51696/51696 [==============================] - 3s 68us/sample - loss: 0.4781 - acc: 0.8679\n",
      "Epoch 14/30\n",
      "51696/51696 [==============================] - 4s 68us/sample - loss: 0.4706 - acc: 0.8698\n",
      "Epoch 15/30\n",
      "51696/51696 [==============================] - 3s 65us/sample - loss: 0.4619 - acc: 0.8727\n",
      "Epoch 16/30\n",
      "51696/51696 [==============================] - 4s 68us/sample - loss: 0.4568 - acc: 0.8732\n",
      "Epoch 17/30\n",
      "51696/51696 [==============================] - 3s 64us/sample - loss: 0.4477 - acc: 0.8764\n",
      "Epoch 18/30\n",
      "51696/51696 [==============================] - 3s 65us/sample - loss: 0.4418 - acc: 0.8774\n",
      "Epoch 19/30\n",
      "51696/51696 [==============================] - 3s 65us/sample - loss: 0.4356 - acc: 0.8812\n",
      "Epoch 20/30\n",
      "51696/51696 [==============================] - 4s 76us/sample - loss: 0.4288 - acc: 0.8815\n",
      "Epoch 21/30\n",
      "51696/51696 [==============================] - 5s 99us/sample - loss: 0.4225 - acc: 0.8846\n",
      "Epoch 22/30\n",
      "51696/51696 [==============================] - 4s 82us/sample - loss: 0.4169 - acc: 0.8860\n",
      "Epoch 23/30\n",
      "51696/51696 [==============================] - 4s 77us/sample - loss: 0.4113 - acc: 0.8869\n",
      "Epoch 24/30\n",
      "51696/51696 [==============================] - 4s 84us/sample - loss: 0.4067 - acc: 0.8879\n",
      "Epoch 25/30\n",
      "51696/51696 [==============================] - 5s 95us/sample - loss: 0.4023 - acc: 0.8904\n",
      "Epoch 26/30\n",
      "51696/51696 [==============================] - 4s 81us/sample - loss: 0.3954 - acc: 0.89200s - loss: 0.3953 - acc: 0.8\n",
      "Epoch 27/30\n",
      "51696/51696 [==============================] - 4s 72us/sample - loss: 0.3913 - acc: 0.8933\n",
      "Epoch 28/30\n",
      "51696/51696 [==============================] - 4s 70us/sample - loss: 0.3861 - acc: 0.8959\n",
      "Epoch 29/30\n",
      "51696/51696 [==============================] - 4s 69us/sample - loss: 0.3809 - acc: 0.8973\n",
      "Epoch 30/30\n",
      "51696/51696 [==============================] - 4s 71us/sample - loss: 0.3784 - acc: 0.8978\n"
     ]
    }
   ],
   "source": [
    "reg_history = reg_model.fit(x_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction:\n",
      "9360/9360 [==============================] - 0s 36us/sample - loss: 0.2586 - acc: 0.9363\n"
     ]
    }
   ],
   "source": [
    "# Using this to tune the drop rate and L2 parameters\n",
    "print('Validation prediction:')\n",
    "score, accuracy = reg_model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction:\n",
      "9364/9364 [==============================] - 0s 36us/sample - loss: 0.2649 - acc: 0.9356\n"
     ]
    }
   ],
   "source": [
    "print('Test prediction:')\n",
    "score, accuracy = reg_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about adding **learning rate decay**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regularization increased the accuracy, though not by much, about **1%**. But now we can safely run even more epochs without the fear of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_model = keras.models.clone_model(reg_model)\n",
    "# We can also try using other algorithms instead of decay in SGD\n",
    "adaptive_model.compile(\n",
    "    optimizer=keras.optimizers.SGD(decay=1e-5), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51696/51696 [==============================] - 4s 77us/sample - loss: 0.9373 - acc: 0.7415\n",
      "Epoch 2/30\n",
      "51696/51696 [==============================] - 4s 71us/sample - loss: 0.6767 - acc: 0.8136\n",
      "Epoch 3/30\n",
      "51696/51696 [==============================] - 3s 65us/sample - loss: 0.6242 - acc: 0.8270\n",
      "Epoch 4/30\n",
      "51696/51696 [==============================] - 4s 70us/sample - loss: 0.5948 - acc: 0.8345\n",
      "Epoch 5/30\n",
      "51696/51696 [==============================] - 4s 71us/sample - loss: 0.5724 - acc: 0.8418\n",
      "Epoch 6/30\n",
      "51696/51696 [==============================] - 4s 73us/sample - loss: 0.5549 - acc: 0.8461\n",
      "Epoch 7/30\n",
      "51696/51696 [==============================] - 4s 74us/sample - loss: 0.5421 - acc: 0.8498\n",
      "Epoch 8/30\n",
      "51696/51696 [==============================] - 4s 75us/sample - loss: 0.5285 - acc: 0.8526\n",
      "Epoch 9/30\n",
      "51696/51696 [==============================] - 4s 74us/sample - loss: 0.5153 - acc: 0.8570\n",
      "Epoch 10/30\n",
      "51696/51696 [==============================] - 4s 74us/sample - loss: 0.5066 - acc: 0.8595\n",
      "Epoch 11/30\n",
      "51696/51696 [==============================] - 4s 77us/sample - loss: 0.4956 - acc: 0.8628\n",
      "Epoch 12/30\n",
      "51696/51696 [==============================] - 4s 79us/sample - loss: 0.4887 - acc: 0.8651\n",
      "Epoch 13/30\n",
      "51696/51696 [==============================] - 4s 81us/sample - loss: 0.4800 - acc: 0.8672\n",
      "Epoch 14/30\n",
      "51696/51696 [==============================] - 4s 82us/sample - loss: 0.4728 - acc: 0.8704\n",
      "Epoch 15/30\n",
      "51696/51696 [==============================] - 4s 71us/sample - loss: 0.4652 - acc: 0.8720\n",
      "Epoch 16/30\n",
      "51696/51696 [==============================] - 4s 72us/sample - loss: 0.4587 - acc: 0.8751\n",
      "Epoch 17/30\n",
      "51696/51696 [==============================] - 4s 74us/sample - loss: 0.4528 - acc: 0.8760\n",
      "Epoch 18/30\n",
      "51696/51696 [==============================] - 4s 77us/sample - loss: 0.4443 - acc: 0.8773\n",
      "Epoch 19/30\n",
      "51696/51696 [==============================] - 4s 78us/sample - loss: 0.4407 - acc: 0.8787\n",
      "Epoch 20/30\n",
      "51696/51696 [==============================] - 4s 77us/sample - loss: 0.4335 - acc: 0.8817\n",
      "Epoch 21/30\n",
      "51696/51696 [==============================] - 4s 80us/sample - loss: 0.4286 - acc: 0.8833\n",
      "Epoch 22/30\n",
      "51696/51696 [==============================] - 4s 76us/sample - loss: 0.4244 - acc: 0.8833\n",
      "Epoch 23/30\n",
      "51696/51696 [==============================] - 4s 71us/sample - loss: 0.4191 - acc: 0.8856\n",
      "Epoch 24/30\n",
      "51696/51696 [==============================] - 4s 72us/sample - loss: 0.4160 - acc: 0.8870\n",
      "Epoch 25/30\n",
      "51696/51696 [==============================] - 4s 74us/sample - loss: 0.4101 - acc: 0.8877\n",
      "Epoch 26/30\n",
      "51696/51696 [==============================] - 4s 85us/sample - loss: 0.4056 - acc: 0.8910\n",
      "Epoch 27/30\n",
      "51696/51696 [==============================] - 4s 76us/sample - loss: 0.4002 - acc: 0.8914\n",
      "Epoch 28/30\n",
      "51696/51696 [==============================] - 4s 74us/sample - loss: 0.3987 - acc: 0.8916\n",
      "Epoch 29/30\n",
      "51696/51696 [==============================] - 4s 73us/sample - loss: 0.3949 - acc: 0.8928\n",
      "Epoch 30/30\n",
      "51696/51696 [==============================] - 4s 75us/sample - loss: 0.3911 - acc: 0.8931\n"
     ]
    }
   ],
   "source": [
    "adaptive_history = adaptive_model.fit(x_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction:\n",
      "9360/9360 [==============================] - 0s 48us/sample - loss: 0.2616 - acc: 0.9347\n"
     ]
    }
   ],
   "source": [
    "print('Validation prediction:')\n",
    "score, accuracy = adaptive_model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction:\n",
      "9364/9364 [==============================] - 0s 36us/sample - loss: 0.2665 - acc: 0.9330\n"
     ]
    }
   ],
   "source": [
    "print('Test prediction:')\n",
    "score, accuracy = adaptive_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rate decay doesn't seem to help much here, results a bit worse. Could try more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What else we can **try**:\n",
    "\n",
    "- load all the available train data\n",
    "- teach for more epochs\n",
    "- try other optimization algorithms, e.g. Adam\n",
    "- play with the number of layers and hidden neurons using validation set\n",
    "- try one-hot output encoding\n",
    "- change activation functions (unlikely)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
