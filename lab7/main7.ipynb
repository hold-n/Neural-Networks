{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекуррентные нейронные сети для анализа текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path('../blobs/aclImdb')\n",
    "train_path = base_path / 'train'\n",
    "test_path = base_path / 'test'\n",
    "\n",
    "EOS = '<EOS>'\n",
    "UNKNOWN = '<UNKNOWN>'\n",
    "vocab = pd.read_csv(base_path / 'imdb.vocab', header=None, squeeze=True)\n",
    "full_vocab = pd.Series([EOS, UNKNOWN]).append(vocab, ignore_index=True)\n",
    "\n",
    "word_to_index = {word: index for index, word in full_vocab.iteritems()}\n",
    "index_to_word = {index: word for index, word in full_vocab.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tf.keras.preprocessing.text.Tokenizer\n",
    "# TODO: consider punctuation as vocabulary entries?\n",
    "\n",
    "def get_words(sentence):\n",
    "    contents = sentence.lower()\n",
    "    contents = re.sub(r'</? *\\w+ */?>', '', contents)\n",
    "    # an approximate list of special characters, should be ok if we disregard some words\n",
    "    # contents = re.sub(r'[.,\\'\"\\-0-9:!?\\(\\)\\n;/*%~&{}$\\-]', ' ', contents)\n",
    "    contents = re.sub(r'\\W', ' ', contents)\n",
    "    contents = re.sub(r'\\d', '', contents)\n",
    "    return contents.split()\n",
    "\n",
    "def read_review(filename):\n",
    "    with open(filename, mode='r') as f:\n",
    "        contents = f.read()\n",
    "        words = get_words(contents)\n",
    "        return [word_to_index.get(word, word_to_index[UNKNOWN]) for word in words]\n",
    "    \n",
    "def get_rating(filename):\n",
    "    return int(filename.stem.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average train review size is 256.75. Truncating all reviews at 250\n",
    "REVIEW_SIZE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train samples, each padded to 250 words\n"
     ]
    }
   ],
   "source": [
    "files = list((train_path / 'pos').glob('*')) + \\\n",
    "    list((train_path / 'neg').glob('*'))\n",
    "x_train = [read_review(name) for name in files]\n",
    "y_train = [get_rating(f) for f in files]\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(\n",
    "    x_train, \n",
    "    value=word_to_index[EOS], \n",
    "    maxlen=REVIEW_SIZE,\n",
    "    padding='post', \n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "x_train, y_train = sklearn.utils.shuffle(np.array(x_train), np.array(y_train))\n",
    "\n",
    "assert(len(x_train) == len(y_train))\n",
    "assert(all(len(s) == len(x_train[0]) for s in x_train))\n",
    "print(len(x_train), 'train samples, each padded to', len(x_train[0]), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 test samples, each padded to 250 words\n"
     ]
    }
   ],
   "source": [
    "files = list((test_path / 'pos').glob('*')) + \\\n",
    "    list((test_path / 'neg').glob('*'))\n",
    "x_test = [read_review(name) for name in files]\n",
    "y_test = [get_rating(f) for f in files]\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(\n",
    "    x_test, \n",
    "    value=word_to_index[EOS], \n",
    "    maxlen=REVIEW_SIZE,\n",
    "    padding='post', \n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "x_test, y_test = sklearn.utils.shuffle(np.array(x_test), np.array(y_test))\n",
    "\n",
    "assert(len(x_test) == len(y_test))\n",
    "assert(all(len(s) == len(x_test[0]) for s in x_test))\n",
    "print(len(x_test), 'test samples, each padded to', len(x_test[0]), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_review(sentence):\n",
    "    return ' '.join(index_to_word[word] for word in sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "a cry in the dark is a masterful piece of cinema haunting and incredibly though provoking the true story of lindy chamberland who in witnessed a horrific sight seeing her month old baby being brutally taken from their family s tent while camping on the austrailian outback azaria the baby was never seen again and the result of her horrendous disappearance caused a true life frenzy all around the world meryl streep does immaculate justice to the role of lindy as she always does but the one thing that helps a cry in the dark never fall flat is the brilliant direction a truly inspired and accurate outlook on this baffeling case tears are brought to the eyes the concept is nothing less then terrifying and afterwards you are left haunted but also inspired <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(x_train))\n",
    "print('Rating:', y_train[i])\n",
    "print(get_processed_review(x_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was going to try using one-hot encoding first just for the sake of it, \n",
    "but with the vocabulary of around 90k words the train dataset would not even fit on the disk drive. Generators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 50)           4476450   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 400)               301200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 4,778,051\n",
      "Trainable params: 4,778,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(len(full_vocab), 50, input_length=REVIEW_SIZE),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(units=200, return_sequences=False)),\n",
    "    keras.layers.Dense(1, activation='elu')\n",
    "])\n",
    "model.compile('adam', 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 508s 20ms/sample - loss: 2.3637\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 515s 21ms/sample - loss: 1.5685\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 523s 21ms/sample - loss: 1.1752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5b43f8fd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrupted the kernel\n",
    "\n",
    "<pre>\n",
    "Epoch 1/3\n",
    "25000/25000 [==============================] - 439s 18ms/sample - loss: 9.6092\n",
    "Epoch 2/3\n",
    "25000/25000 [==============================] - 453s 18ms/sample - loss: 4.0583\n",
    "Epoch 3/3\n",
    " 1184/25000 [>.............................] - ETA: 7:27 - loss: 2.6545</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, np.round(predictions))\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's twice better than a random guess. Still, it's not a classification problem and being close enough is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating: 3.2253666\n",
      "Actual rating: 1\n",
      "\t bolo yeung is in the movie ten minutes altogether including when he s serving iced drinks to his boss a lot of street thugs looking like junkyard keepers get instantly overpowered by the asian superhero who talks like an illegal alien just out of the back of a manure truck thug let this to me shirt off gay model like muscles <UNKNOWN> <UNKNOWN> hee <UNKNOWN> hap hap he s dead on the floor with his neck elbow chin or balls broken cheap semi sex scenes where the white broad come out of nowhere digs the asian superhero norton former c action movies star does nothing but pose as an eccentric trendy weapon smuggler who traffics white slutty girls hand picked at a night club where they willingly follow some idiot posing as a millionaire snapping at them you reap what you sow yes the local police captain is involved and yes the first butchered cop is the former patrol teammate of the super hero <UNKNOWN> action scenes are fake like a hee haw chinese tries some spinning kick b skinny leg of chinese to the throat of negro thug c finishing death move to his head too much like walker texas ranger fake action end titles <UNKNOWN> rubbish those people are good enough only to be stand ins or body doubles in other c movies and be credited at most collectively as stunt crew provided by the county prison <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Predicted Rating: 2.6028612\n",
      "Actual rating: 4\n",
      "\t carmen is a prostitute that lives seducing and stealing soldiers of the spanish army she is without any doubt the best femme fatale at the moment when a man resist her charming attentions she decides to do everything to destroy him at the end he falls in her web and he will be forced to make all the things he ever hated only for being with carmen despite paz vega is very beautiful she doesn t seem a gypsy as carmen is and neither her acting nor <UNKNOWN> s are good the story results very boring and in most moments it is very absurd while intending to appear truthful in the same way are the scenarios and the special effects despite not being but they are not but acceptable and too much artificial for a historic film as it is to sum up boring and bad with a very absurd development there are much betters thing to watch <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Predicted Rating: 2.320261\n",
      "Actual rating: 2\n",
      "\t this film is sometimes called the story of o pt which tries to pass itself off as a sequel of sorts to the french erotic s m thriller the story of o although i ve never seen the original version i did however get to see this sorry mixed bag of sexual social politics i guess the o angle comes from the occasional s m overtones which were never as explicit and unpleasant to watch as the ones in mistress klaus kinski is the only recognizable face in this french japanese production but speaks his lines in english at least in the version i saw the unnecessary use of surrealism only manages to make this some what boring example in pseudo porn even more pretentious what are they trying to prove with depicting a piano floating in water it s obvious that after the whole porno chic trend in cinema petered out ouch sorry bad pun about producers had to scrape the bottom of the barrel trying to please the mavens of adult cinema not to mention foreign art cinema so film goers had to contend with dreck like the last woman and others like it <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    i = np.random.randint(len(x_test))\n",
    "    print('Predicted Rating:', predictions[i])\n",
    "    print('Actual rating:', y_test[i])\n",
    "    print('\\t', get_processed_review(x_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
